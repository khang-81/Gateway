# Production Docker Compose Configuration
# Features:
# - Resource limits for scaling
# - Logging driver for request/cost tracking
# - Health checks
# - Support for Docker Swarm/Kubernetes scaling
# - Load balancer (nginx) for multiple instances

services:
  mlflow-gateway:
    build:
      context: .
      dockerfile: Dockerfile
    # Remove container_name when scaling - Docker Compose will auto-generate names
    # container_name: mlflow-gateway-prod
    # Don't expose ports directly when scaling - use nginx load balancer
    expose:
      - "5000"
    # Don't mount config.yaml - entrypoint will create it dynamically
    env_file:
      - .env
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
    restart: unless-stopped
    # Resource limits (works with docker compose up -d --scale)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        labels: "production,mlflow-gateway"
    networks:
      - mlflow-network

  # Nginx load balancer for multiple gateway instances
  nginx:
    image: nginx:alpine
    container_name: mlflow-gateway-nginx
    ports:
      - "5000:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      mlflow-gateway:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - mlflow-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

networks:
  mlflow-network:
    driver: bridge
