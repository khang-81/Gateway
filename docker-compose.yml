services:
  mlflow-gateway:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mlflow-gateway
    ports:
      - "5000:5000"
    # Don't mount config.yaml - entrypoint will create it dynamically with API key
    # volumes:
    #   - ./config.yaml:/opt/mlflow/config.yaml:ro
    env_file:
      - .env
    environment:
      # Pass OPENAI_API_KEY from .env file
      # Note: Make sure .env file exists and contains OPENAI_API_KEY=your_key
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "mlflow-gateway"

# Optional: Nginx reverse proxy for dev (uncomment to use)
#  nginx:
#    image: nginx:alpine
#    container_name: mlflow-gateway-nginx
#    ports:
#      - "80:80"
#    volumes:
#      - ./nginx.conf:/etc/nginx/nginx.conf:ro
#    depends_on:
#      - mlflow-gateway
#    restart: unless-stopped
